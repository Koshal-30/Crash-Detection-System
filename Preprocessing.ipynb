{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd8a6ce-40d1-4379-af6a-4b71165b536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e476b047-095d-4185-85ed-a4649a9fd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= CONFIG =================\n",
    "DATASET_PATH = r\"D:\\Car Crash Detection\\videos\"\n",
    "SAVE_DIR = r\"D:\\Car Crash Detection\\processed\"\n",
    "\n",
    "IMG_SIZE = 160\n",
    "SEQUENCE_LENGTH = 12\n",
    "\n",
    "CLASSES = {\n",
    "    \"Crash\": 1,\n",
    "    \"Normal\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1220d4-ad2b-4920-8b22-2bdd03cd4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, sequence_length=SEQUENCE_LENGTH):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames <= 0:\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, sequence_length).astype(int)\n",
    "\n",
    "    current_frame = 0\n",
    "    frame_pos = 0\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame is None:\n",
    "                break\n",
    "\n",
    "            if frame_pos < sequence_length and current_frame == frame_indices[frame_pos]:\n",
    "                frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = frame.astype(\"float32\") / 255.0\n",
    "                frames.append(frame)\n",
    "                frame_pos += 1\n",
    "\n",
    "            current_frame += 1\n",
    "            if frame_pos >= sequence_length:\n",
    "                break\n",
    "\n",
    "    except Exception:\n",
    "        cap.release()\n",
    "        return None\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return None\n",
    "\n",
    "    # Pad short videos\n",
    "    while len(frames) < sequence_length:\n",
    "        frames.append(frames[-1])\n",
    "\n",
    "    return np.array(frames, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a12e65-5d1e-495f-b53f-69a2faa96c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tensors to: D:\\Car Crash Detection\\processed\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving tensors to:\", os.path.abspath(SAVE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba9c032-1aa9-42c5-83b9-6304cb9f9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset_path, save_dir=SAVE_DIR):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    saved_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for class_name, label in CLASSES.items():\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "\n",
    "        for video_file in tqdm(os.listdir(class_path), desc=f\"Processing {class_name}\"):\n",
    "            video_path = os.path.join(class_path, video_file)\n",
    "\n",
    "            frames = extract_frames(video_path)\n",
    "            if frames is None:\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "\n",
    "            # ✅ FIX: include class name to avoid overwriting\n",
    "            base_name = os.path.splitext(video_file)[0]\n",
    "            file_id = f\"{class_name}_{base_name}\"\n",
    "\n",
    "            X_path = os.path.join(save_dir, f\"{file_id}_X.npy\")\n",
    "            y_path = os.path.join(save_dir, f\"{file_id}_y.npy\")\n",
    "\n",
    "            # Resume-safe: skip already processed files\n",
    "            if os.path.exists(X_path) and os.path.exists(y_path):\n",
    "                continue\n",
    "\n",
    "            np.save(X_path, frames)\n",
    "            np.save(y_path, label)\n",
    "            saved_count += 1\n",
    "\n",
    "    print(\"✅ Preprocessing complete\")\n",
    "    print(\"Saved videos :\", saved_count)\n",
    "    print(\"Skipped videos :\", skipped_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148b5b15-f9e9-4115-980c-b6d73c5556e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Crash: 100%|████████████████████████████████████████████████████████████| 1500/1500 [05:46<00:00,  4.32it/s]\n",
      "Processing Normal: 100%|███████████████████████████████████████████████████████████| 3000/3000 [11:38<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing complete\n",
      "Saved videos : 4500\n",
      "Skipped videos : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_dataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5986433d-22f7-4bdb-9377-6511caadf5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X files: 4500\n",
      "y files: 4500\n",
      "Total files: 9000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "X_files = glob.glob(r\"D:\\Car Crash Detection\\processed\\*_X.npy\")\n",
    "y_files = glob.glob(r\"D:\\Car Crash Detection\\processed\\*_y.npy\")\n",
    "\n",
    "print(\"X files:\", len(X_files))\n",
    "print(\"y files:\", len(y_files))\n",
    "print(\"Total files:\", len(X_files) + len(y_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fe6a2-63cc-44a8-aeb9-88b98ae97f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b1116-e635-4a33-8444-f68af21ffcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_files = sorted(glob.glob(\"processed/*_X.npy\"))\n",
    "y_files = sorted(glob.glob(\"processed/*_y.npy\"))\n",
    "\n",
    "assert len(X_files) == len(y_files), \"❌ X/Y file count mismatch\"\n",
    "\n",
    "print(\"Total samples:\", len(X_files))\n",
    "\n",
    "# Train / temp split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_files,\n",
    "    y_files,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation / test split\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(X_train))\n",
    "print(\"Validation:\", len(X_val))\n",
    "print(\"Test:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819e4c7-742e-4fad-bc4e-67af414e25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X_files, y_files, batch_size=2, shuffle=True):\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            combined = list(zip(X_files, y_files))\n",
    "            np.random.shuffle(combined)\n",
    "            X_files, y_files = zip(*combined)\n",
    "\n",
    "        for i in range(0, len(X_files), batch_size):\n",
    "            X_batch, y_batch = [], []\n",
    "\n",
    "            for j in range(i, min(i + batch_size, len(X_files))):\n",
    "                X_batch.append(np.load(X_files[j]))\n",
    "                y_batch.append(np.load(y_files[j]))\n",
    "\n",
    "            yield np.array(X_batch), np.array(y_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a77700-feba-4952-85ad-40858cc987c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    TimeDistributed, Conv2D, MaxPooling2D,\n",
    "    Flatten, LSTM, Dense, Dropout\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    input_shape=(SEQUENCE_LENGTH, IMG_SIZE, IMG_SIZE, 3)\n",
    "))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
    "\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(64, (3,3), activation=\"relu\")\n",
    "))\n",
    "model.add(TimeDistributed(MaxPooling2D((2,2))))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ac2a7-44b2-4674-8d7e-7a70cf616adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "model.fit(\n",
    "    data_generator(X_train, y_train, BATCH_SIZE),\n",
    "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "    validation_data=data_generator(X_val, y_val, BATCH_SIZE),\n",
    "    validation_steps=len(X_val) // BATCH_SIZE,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee3d03-b102-4802-86c7-a45c85d7cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    data_generator(X_test, y_test, BATCH_SIZE),\n",
    "    steps=len(X_test) // BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
